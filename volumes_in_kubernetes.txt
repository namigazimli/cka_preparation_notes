Docker containers are meant to be transient in nature which means they are meant to last only for a short period of time. They are called upon
when required to process data and destroyed once finished. The same is true for the data within the container, the data is destroyed along with 
the container. To persist data processed by the containers we attach a volume to the containers when they are created. The data processed by the container is now placed in this volume thereby retaining it permanently. Even if the container is deleted, the data generated or processed by it remains. So how does it work in Kubernetes world? Just as in Docker, the Pods created in Kubernetes are transient in nature. When a Pod is created to process data and then deleted, the data processed by it gets deleted as well. For this we attach a volume to the Pod. The data generated by the POD is now stored in the volume, and even after the POD is deleted, the data remains. We create a simple POD that generates a random number between 1 and 100, and writes that to the file at /opt/number.out. It then gets deleted along with the random number. To retain number generated by the POD we create a volume and a volume needs a storage. When you create a volume, you can choose to configure its storage in different ways.
In this case we specify a path /data on the host. This way any files created in the volume would be stored in the directory /data on the node. Once the volume is created, to access it from a container we mount the volume to a directory inside the container. We use the volumeMounts field in each container to mount the data-volume to the directory /opt within the container. The random number will now be written to /opt mount inside the container, which happens to be on the data-volume which is in fact /data directory on the host. When the pod gets deleted, the file with the random number still lives on the host. 

-----------------------------------------------------------------
pod-definition.yaml						|
-----------------------------------------------------------------
apiVersion: v1							|
kind: Pod							|
metadata:							|
  name: random-number-generator					|
spec:								|  						|
  containers:							|
  - image: alpine						|
    name: alpine						|
    command: ["/bin/sh","-c"]					|
    args: ["shuf -i 0-100 -n 1 >> /opt/number.out;"]		|
    volumeMounts:						|
    - mountPath: /opt						|
      name: data-volume						|
  volumes:							|
  - name: data-volume						|
    hostPath:							|
      path: /data						|
      type: Directory						|
-----------------------------------------------------------------

Let's take a step back and look at the volume storage options. We just used the hostPath option to configure a directory and the host as storage space for the volume. Now that works fine on a single node. However it is not recommended for use in a multi-node cluster. This is because the Pods would use the /data directory on all the nodes, and expect all of them to be the same and have the same data. Since they are on different servers they are in fact not the same unless you configure some kind of external replicated cluster storage solution. Kubernetes supports several types of standard storage solutions such as NFS, GlusterFS, Flocker, FibreChannel, CephFS, ScaleIO or public cloud solutions like AWS EBS, Azure Disk or File or Google's Persistent Disk. For example, to configure an AWS EBS volume as the storage option for the volume, we replace hostPath field of the volume with awsElasticBlockStore field along with the volumeID and fsType. The volume storage will now be on AWS EBS. 

---------------------------------
volumes:			|
- name: data-volume		|
  awsElasticBlockStore:		|
    volumeID: <volume-id>	|
    fstype: ext4 		|
---------------------------------
